{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxhormazabal/depencendy_parsing/blob/main/p2_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiIjtQIW-xwx"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "## Installation of dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgvUH3m47oHY",
        "outputId": "a53c775d-47a1-49b3-e8dc-327eb5e018b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: conllu in /usr/local/lib/python3.8/dist-packages (4.5.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install conllu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqe_9RpC-94T"
      },
      "source": [
        "## Connecting to Google Drive to read the `.py` file that contains the functions to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owHKXmFn1BPs",
        "outputId": "c2c7734b-209b-43bd-979d-f387a7732964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Getting access to Google Drive files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LIpSqrDi3HrT"
      },
      "outputs": [],
      "source": [
        "# Import our own functions (they are in a .py file on Google Drive)\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/MASTER\")\n",
        "from nlu_preprocessing_utils import *\n",
        "from conllu import parse\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXfZhJypTFoh"
      },
      "source": [
        "## Preprocessing in One Step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igfT-ibOTFBq",
        "outputId": "854b8697-e731-45ef-b31f-24606ad7cfa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data sucessfully saved on ./ nlu_data/4stack8buffer\n"
          ]
        }
      ],
      "source": [
        "base_url = 'https://raw.githubusercontent.com/UniversalDependencies/UD_English-ParTUT/master/'\n",
        "file_basename = 'en_partut-ud'\n",
        "stack_len = 4\n",
        "buffer_len = 8\n",
        "\n",
        "(path,x_train_token,action_encod_train,deprel_encod_train,x_test_token,action_encod_test,deprel_encod_test,x_val_token,action_encod_val,deprel_encod_val) = preprocessingOneStep(base_url,file_basename,stack_len,buffer_len)\n",
        "!mkdir -p {path}\n",
        "saveData(path,x_train_token,action_encod_train,deprel_encod_train,x_test_token,action_encod_test,deprel_encod_test,x_val_token,action_encod_val,deprel_encod_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = 'https://raw.githubusercontent.com/UniversalDependencies/UD_English-ParTUT/master/'\n",
        "file_basename = 'en_partut-ud'\n",
        "stack_len = 5\n",
        "buffer_len = 5\n",
        "\n",
        "(path,x_train_token,action_encod_train,deprel_encod_train,x_test_token,action_encod_test,deprel_encod_test,x_val_token,action_encod_val,deprel_encod_val) = preprocessingOneStep(base_url,file_basename,stack_len,buffer_len)\n",
        "!mkdir -p {path}\n",
        "saveData(path,x_train_token,action_encod_train,deprel_encod_train,x_test_token,action_encod_test,deprel_encod_test,x_val_token,action_encod_val,deprel_encod_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQHjLBj-w0sl",
        "outputId": "8715c9d1-4b21-4cb5-bc58-87703aeef288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data sucessfully saved on ./ nlu_data/5stack5buffer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = 'https://raw.githubusercontent.com/UniversalDependencies/UD_English-ParTUT/master/'\n",
        "file_basename = 'en_partut-ud'\n",
        "stack_len = 7\n",
        "buffer_len = 10\n",
        "\n",
        "(path,x_train_token,action_encod_train,deprel_encod_train,x_test_token,action_encod_test,deprel_encod_test,x_val_token,action_encod_val,deprel_encod_val) = preprocessingOneStep(base_url,file_basename,stack_len,buffer_len)\n",
        "!mkdir -p {path}\n",
        "saveData(path,x_train_token,action_encod_train,deprel_encod_train,x_test_token,action_encod_test,deprel_encod_test,x_val_token,action_encod_val,deprel_encod_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3z_jhTEw3e1",
        "outputId": "affde6f4-2883-4af3-b23c-c605e58c84d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data sucessfully saved on ./ nlu_data/7stack10buffer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SOj67OF_IYX"
      },
      "source": [
        "## Reading datasource from its origin on github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7xYLYzM18CJL"
      },
      "outputs": [],
      "source": [
        "# English\n",
        "# 'https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-train.conllu'\n",
        "# https://raw.githubusercontent.com/UniversalDependencies/UD_English-ParTUT/master/en_partut-ud-train.conllu\n",
        "\n",
        "base_url = 'https://raw.githubusercontent.com/UniversalDependencies/UD_English-ParTUT/master/'\n",
        "file_basename = 'en_partut-ud'\n",
        "(en_train,en_test,en_val) = readConlluDataset(base_url,file_basename)\n",
        "en_upo2number, en_number2upo, en_nupos = getUposList(en_train)\n",
        "number2action,action2number = getActionDict()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm nlu_data/original_test.conllu\n",
        "generateConlluForTesting()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtLX9WVJgJp3",
        "outputId": "730b574c-8542-4a76-f564-050c544c247f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original file generated in nlu_data/original_test_line.conllu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNc5Q7KP_Mz2"
      },
      "source": [
        "## Transforming the data source into the initial dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f4LZejqf8QKV"
      },
      "outputs": [],
      "source": [
        "train_df = conlluToDatasetForDependency(en_train,en_upo2number)\n",
        "test_df = conlluToDatasetForDependency(en_test,en_upo2number)\n",
        "val_df = conlluToDatasetForDependency(en_val,en_upo2number)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iYQ0mso4wDW"
      },
      "source": [
        "### Checking Projective Arcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JbVcuJGzvz3Q"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.iloc[projectiveArcs(train_df)]\n",
        "test_df = test_df.iloc[projectiveArcs(test_df)]\n",
        "val_df = val_df.iloc[projectiveArcs(val_df)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "rZXo4ZCwKCw2",
        "outputId": "b9c7f881-49d3-40cf-a5a6-979f5d37bc25"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     id  \\\n",
              "0           [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]   \n",
              "1       [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]   \n",
              "2     [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "3                                                [1, 2]   \n",
              "4           [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]   \n",
              "...                                                 ...   \n",
              "1776  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "1777  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "1778  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "1779  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
              "1780                    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   \n",
              "\n",
              "                                                   form  \\\n",
              "0     [Distribution, of, this, license, does, not, c...   \n",
              "1     [Creative, Commons, provides, this, informatio...   \n",
              "2     [Creative, Commons, makes, no, warranties, reg...   \n",
              "3                                          [License, .]   \n",
              "4     [The, work, is, protected, by, copyright, and,...   \n",
              "...                                                 ...   \n",
              "1776  [From, the, 18, th, century, ,, the, desire, f...   \n",
              "1777  [That, demand, also, led, to, the, production,...   \n",
              "1778  [Shakespeare, 's, works, include, the, 36, pla...   \n",
              "1779  [Two, plays, not, included, in, the, First, Fo...   \n",
              "1780  [No, Shakespearean, poems, were, included, in,...   \n",
              "\n",
              "                                                   head  \\\n",
              "0             [7, 4, 4, 1, 7, 7, 0, 12, 12, 9, 9, 7, 7]   \n",
              "1      [3, 1, 0, 5, 3, 13, 13, 11, 11, 9, 13, 11, 3, 3]   \n",
              "2     [3, 1, 0, 5, 3, 5, 8, 6, 8, 12, 12, 3, 12, 15,...   \n",
              "3                                                [0, 1]   \n",
              "4            [2, 4, 4, 0, 6, 4, 12, 9, 7, 12, 12, 6, 4]   \n",
              "...                                                 ...   \n",
              "1776  [5, 5, 5, 3, 13, 5, 8, 13, 12, 12, 12, 8, 0, 1...   \n",
              "1777  [2, 4, 4, 0, 7, 7, 4, 11, 11, 11, 7, 18, 18, 1...   \n",
              "1778  [3, 1, 4, 0, 7, 7, 4, 7, 12, 12, 12, 8, 14, 12...   \n",
              "1779  [2, 23, 4, 2, 8, 8, 8, 4, 2, 13, 13, 13, 2, 15...   \n",
              "1780                     [3, 3, 5, 5, 0, 9, 9, 9, 5, 5]   \n",
              "\n",
              "                                                 deprel  \\\n",
              "0     [nsubj, case, det, nmod, aux, advmod, root, de...   \n",
              "1     [nsubj, flat, root, det, obj, case, det, punct...   \n",
              "2     [nsubj, flat, root, det, obj, acl, det, obj, a...   \n",
              "3                                         [root, punct]   \n",
              "4     [det, nsubj:pass, aux:pass, root, case, obl, c...   \n",
              "...                                                 ...   \n",
              "1776  [case, det, nummod, amod, obl, punct, det, nsu...   \n",
              "1777  [det, nsubj, advmod, root, case, det, obl, cas...   \n",
              "1778  [nmod, case, nsubj, root, det, nummod, obj, ac...   \n",
              "1779  [nummod, nsubj:pass, advmod, acl, case, det, a...   \n",
              "1780  [det, amod, nsubj:pass, aux:pass, root, case, ...   \n",
              "\n",
              "                                                   upos  \n",
              "0               [1, 2, 3, 1, 4, 5, 6, 3, 1, 7, 1, 1, 7]  \n",
              "1            [8, 8, 6, 3, 1, 2, 3, 7, 2, 7, 6, 7, 1, 7]  \n",
              "2     [8, 8, 6, 3, 1, 6, 3, 1, 6, 7, 9, 6, 1, 2, 1, ...  \n",
              "3                                                [1, 7]  \n",
              "4             [3, 1, 4, 6, 2, 1, 9, 7, 9, 10, 10, 1, 7]  \n",
              "...                                                 ...  \n",
              "1776  [2, 3, 13, 10, 1, 7, 3, 1, 2, 10, 8, 1, 6, 1, ...  \n",
              "1777  [3, 1, 11, 6, 2, 3, 1, 2, 10, 10, 1, 7, 11, 11...  \n",
              "1778  [8, 5, 1, 6, 3, 13, 1, 6, 2, 3, 10, 1, 2, 13, ...  \n",
              "1779  [13, 1, 5, 6, 2, 3, 10, 1, 7, 3, 13, 10, 1, 9,...  \n",
              "1780                   [3, 10, 1, 4, 6, 2, 3, 10, 1, 7]  \n",
              "\n",
              "[1748 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c3c9d42-34cf-425d-9bcf-f2d6c9d8ac41\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>form</th>\n",
              "      <th>head</th>\n",
              "      <th>deprel</th>\n",
              "      <th>upos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]</td>\n",
              "      <td>[Distribution, of, this, license, does, not, c...</td>\n",
              "      <td>[7, 4, 4, 1, 7, 7, 0, 12, 12, 9, 9, 7, 7]</td>\n",
              "      <td>[nsubj, case, det, nmod, aux, advmod, root, de...</td>\n",
              "      <td>[1, 2, 3, 1, 4, 5, 6, 3, 1, 7, 1, 1, 7]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]</td>\n",
              "      <td>[Creative, Commons, provides, this, informatio...</td>\n",
              "      <td>[3, 1, 0, 5, 3, 13, 13, 11, 11, 9, 13, 11, 3, 3]</td>\n",
              "      <td>[nsubj, flat, root, det, obj, case, det, punct...</td>\n",
              "      <td>[8, 8, 6, 3, 1, 2, 3, 7, 2, 7, 6, 7, 1, 7]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[Creative, Commons, makes, no, warranties, reg...</td>\n",
              "      <td>[3, 1, 0, 5, 3, 5, 8, 6, 8, 12, 12, 3, 12, 15,...</td>\n",
              "      <td>[nsubj, flat, root, det, obj, acl, det, obj, a...</td>\n",
              "      <td>[8, 8, 6, 3, 1, 6, 3, 1, 6, 7, 9, 6, 1, 2, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>[License, .]</td>\n",
              "      <td>[0, 1]</td>\n",
              "      <td>[root, punct]</td>\n",
              "      <td>[1, 7]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]</td>\n",
              "      <td>[The, work, is, protected, by, copyright, and,...</td>\n",
              "      <td>[2, 4, 4, 0, 6, 4, 12, 9, 7, 12, 12, 6, 4]</td>\n",
              "      <td>[det, nsubj:pass, aux:pass, root, case, obl, c...</td>\n",
              "      <td>[3, 1, 4, 6, 2, 1, 9, 7, 9, 10, 10, 1, 7]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1776</th>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[From, the, 18, th, century, ,, the, desire, f...</td>\n",
              "      <td>[5, 5, 5, 3, 13, 5, 8, 13, 12, 12, 12, 8, 0, 1...</td>\n",
              "      <td>[case, det, nummod, amod, obl, punct, det, nsu...</td>\n",
              "      <td>[2, 3, 13, 10, 1, 7, 3, 1, 2, 10, 8, 1, 6, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1777</th>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[That, demand, also, led, to, the, production,...</td>\n",
              "      <td>[2, 4, 4, 0, 7, 7, 4, 11, 11, 11, 7, 18, 18, 1...</td>\n",
              "      <td>[det, nsubj, advmod, root, case, det, obl, cas...</td>\n",
              "      <td>[3, 1, 11, 6, 2, 3, 1, 2, 10, 10, 1, 7, 11, 11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1778</th>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[Shakespeare, 's, works, include, the, 36, pla...</td>\n",
              "      <td>[3, 1, 4, 0, 7, 7, 4, 7, 12, 12, 12, 8, 14, 12...</td>\n",
              "      <td>[nmod, case, nsubj, root, det, nummod, obj, ac...</td>\n",
              "      <td>[8, 5, 1, 6, 3, 13, 1, 6, 2, 3, 10, 1, 2, 13, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1779</th>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
              "      <td>[Two, plays, not, included, in, the, First, Fo...</td>\n",
              "      <td>[2, 23, 4, 2, 8, 8, 8, 4, 2, 13, 13, 13, 2, 15...</td>\n",
              "      <td>[nummod, nsubj:pass, advmod, acl, case, det, a...</td>\n",
              "      <td>[13, 1, 5, 6, 2, 3, 10, 1, 7, 3, 13, 10, 1, 9,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1780</th>\n",
              "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
              "      <td>[No, Shakespearean, poems, were, included, in,...</td>\n",
              "      <td>[3, 3, 5, 5, 0, 9, 9, 9, 5, 5]</td>\n",
              "      <td>[det, amod, nsubj:pass, aux:pass, root, case, ...</td>\n",
              "      <td>[3, 10, 1, 4, 6, 2, 3, 10, 1, 7]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1748 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c3c9d42-34cf-425d-9bcf-f2d6c9d8ac41')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1c3c9d42-34cf-425d-9bcf-f2d6c9d8ac41 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1c3c9d42-34cf-425d-9bcf-f2d6c9d8ac41');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woj7d4j97H01"
      },
      "source": [
        "## Training the Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QB-ErugJ7HRu"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "text = \"root\"\n",
        "\n",
        "for sentence in train_df['form']:\n",
        "  for word in sentence:\n",
        "    text = text + \" \" + word\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\",filters=\"\") \n",
        "tokenizer.fit_on_texts([text])\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "#save\n",
        "with open('nlu_data/tokenizer.json', 'w') as outfile:\n",
        "    outfile.write(tokenizer.to_json())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EecN_ANSJTf"
      },
      "source": [
        "## Post-Oracle datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "X5tru6AGOArC"
      },
      "outputs": [],
      "source": [
        "stack_len = 3\n",
        "buffer_len = 5\n",
        "(x_train,action_train,deprel_train) = transformByOracle(train_df,stack_len,buffer_len,en_nupos)\n",
        "(x_test,action_test,deprel_test) = transformByOracle(test_df,stack_len,buffer_len,en_nupos)\n",
        "(x_val,action_val,deprel_val) = transformByOracle(val_df,stack_len,buffer_len,en_nupos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvxR1N9VSZGw"
      },
      "source": [
        "## X-Variables Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "z8Miykzx2PBc"
      },
      "outputs": [],
      "source": [
        "x_train_token = applyTokenizer(x_train,stack_len,buffer_len,tokenizer)\n",
        "x_test_token = applyTokenizer(x_test,stack_len,buffer_len,tokenizer)\n",
        "x_val_token = applyTokenizer(x_val,stack_len,buffer_len,tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnDgk2riSd04"
      },
      "source": [
        "## Y-Variables encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9u1S3Q1aSisk"
      },
      "outputs": [],
      "source": [
        "deprel_train,number2deprel_train,deprel2number_train = deprelToNumerical(deprel_train)\n",
        "deprel_test,number2deprel_test,deprel2number_test = deprelToNumerical(deprel_test)\n",
        "deprel_val,number2deprel_val,deprel2number_val = deprelToNumerical(deprel_val)\n",
        "\n",
        "action_encod_train = tf.keras.utils.to_categorical(action_train)\n",
        "deprel_encod_train = tf.keras.utils.to_categorical(deprel_train)\n",
        "action_encod_test = tf.keras.utils.to_categorical(action_test)\n",
        "deprel_encod_test = tf.keras.utils.to_categorical(deprel_test)\n",
        "action_encod_val = tf.keras.utils.to_categorical(action_val)\n",
        "deprel_encod_val = tf.keras.utils.to_categorical(deprel_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz78ero_mu9C"
      },
      "source": [
        "### Making lengths of deprel equal between sets. Using the maximum value of deprels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-VnhqHyplkU-"
      },
      "outputs": [],
      "source": [
        "max_len = max([deprel_encod_train.shape[1],deprel_encod_test.shape[1],deprel_encod_val.shape[1]])\n",
        "\n",
        "deprel_encod_train = tf.keras.utils.pad_sequences(deprel_encod_train,maxlen=max_len,padding='post')\n",
        "deprel_encod_test = tf.keras.utils.pad_sequences(deprel_encod_test,maxlen=max_len,padding='post')\n",
        "deprel_encod_val = tf.keras.utils.pad_sequences(deprel_encod_val,maxlen=max_len,padding='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAAazY0lYlsk"
      },
      "source": [
        "Creating folder to save the data depending of the size of stack and buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8xi2j9DYlHA"
      },
      "outputs": [],
      "source": [
        "folder_name = str(stack_len)+\"stack\"+str(buffer_len)+\"buffer\"\n",
        "path = \"nlu_data/\"+folder_name\n",
        "!mkdir -p {path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vygXFJpeNJ7C"
      },
      "outputs": [],
      "source": [
        "# function to save the numpy array as a file and re-use it avoiding preprocessing steps\n",
        "# It will be save in your current directory (seted in \"os.chdir(\"/content/drive/MyDrive/MASTER\")\")\n",
        "\n",
        "# Saving train data\n",
        "np.save(path+'/x_train.npy', x_train_token) \n",
        "np.save(path+'/action_train.npy', action_encod_train)\n",
        "np.save(path+'/deprel_train.npy', deprel_encod_train)\n",
        "\n",
        "# Saving test data\n",
        "np.save(path+'/x_test.npy', x_test_token) \n",
        "np.save(path+'/action_test.npy', action_encod_test)\n",
        "np.save(path+'/deprel_test.npy', deprel_encod_test)\n",
        "\n",
        "# Saving val data\n",
        "np.save(path+'/x_val.npy', x_val_token) \n",
        "np.save(path+'/action_val.npy', action_encod_val)\n",
        "np.save(path+'/deprel_val.npy', deprel_encod_val)\n",
        "\n",
        "# With the following you can read the file and create the numpy array again\n",
        "# new_x_data = np.load('x_data.npy',allow_pickle=True)\n",
        "# new_action_data = np.load('action_data.npy',allow_pickle=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbSWqOEd2Pybi2UnpKonZX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}